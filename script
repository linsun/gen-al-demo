kubectl exec -it deploy/client -- curl http://ollama.ollama:80/api/generate -d '{"model": "llama3.2", "prompt":"what are the top 1 favorite place in Salt Lake City?", "stream": false}'



for i in {2..10009}
do
  kubectl exec -it deploy/client -- curl http://ollama.ollama:80/api/tags
  sleep 5
done

for i in {2..10009}
do
  kubectl exec -it deploy/client -- curl http://ollama.ollama:80/api/generate -d '{"model": "llama3.2", "prompt":"what are the top 1 favorite place in Salt Lake City?", "stream": false}'
done

kubectl port-forward -n ollama service/ollama 11434:80
kubectl port-forward service/demo 8501:8501

ollama pull llama3.2
ollama pull llava

curl http://localhost:11434/api/generate -d '{
  "model": "llama3.2",
  "prompt": "what are the top 2 favorite places in Salt Lake City?",
  "stream": false
}'

# pull models
kubectl exec -it deploy/client -- curl http://ollama.ollama:80/api/pull -d '{"name": "llama3.2"}'
kubectl exec -it deploy/client -- curl http://ollama.ollama:80/api/pull -d '{"name": "llava"}'

# list models
kubectl exec -it deploy/client -- curl http://ollama.ollama:80/api/tags


curl http://localhost:11434/api/chat -d '{
  "model": "llama3.2",
  "messages": [
    {"role": "user", "content": "what are top 2 favorite places in Salt Lake City?"}
  ],
  "stream": false
}'

kubectl exec -it deploy/client -- curl http://ollama.ollama:80/api/chat -d '{"model": "llama3.2", "messages": [{"role": "user", "content": "what are top 2 favorite places in Salt Lake City?"}], "stream": false}'

curl http://localhost:11434/api/chat -d '{
  "model": "llama3.2", 
  "messages": [
    {"role": "user", "content": "what are top 2 favorite places in Salt Lake City?"}
  ], 
  "stream": true
}'

for i in {2..10009}
do
  k exec -it deploy/client -- curl http://httpbin.org/get -v
done

for i in {1..100}
do
  curl -X POST http://rag-service:80/upload -H "Content-Type: multipart/form-data" -F "file=@ambient.txt;type=text/plain"
  sleep 5
done

kubectl exec -it deploy/client -- curl http://host.docker.internal:11434/api/tags

kubectl exec -it deploy/client -- curl http://ollama.ollama:80/api/tags